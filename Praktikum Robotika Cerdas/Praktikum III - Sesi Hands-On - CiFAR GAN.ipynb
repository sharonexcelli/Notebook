{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJp-D51g0IDd"
   },
   "source": [
    "## **1) Importing Python Packages for GAN**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1k5mFBuzzl2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file generated_images already exists.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10, mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "!mkdir generated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr-eZOzg0X79"
   },
   "source": [
    "## **2) Parameters for Neural Networks & Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RThZMDruz9cB",
    "outputId": "e4b60954-991f-4cbb-9bdf-38717f20518a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "img_width = 32\n",
    "img_height = 32\n",
    "channels = 3\n",
    "img_shape = (img_width, img_height, channels)\n",
    "latent_dim = 100\n",
    "adam = Adam(lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3bcJZZg0cqy"
   },
   "source": [
    "## **3) Building Generator**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NdiqZpri0iQh",
    "outputId": "eff07f93-2f5d-4bfb-b2be-b7d00839b15d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 4096)              413696    \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 4096)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        524416    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 128)      262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 128)      262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 3)         3459      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,466,115\n",
      "Trainable params: 1,466,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Create first layer, to receive the input \n",
    "    model.add(Dense(256 * 4 * 4, input_dim = latent_dim))\n",
    "    # 256 * 8 * 8; for upscaling the layers, \n",
    "    # initial shape to construct into final shape\n",
    "\n",
    "    # Create default activation function\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "\n",
    "    # Create reshape layer\n",
    "    model.add(Reshape((4, 4,256)))\n",
    "    # 8,8,256 ; reffers to first layer\n",
    "\n",
    "    # Adding more layers for neurons and better result\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha= 0.2))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha= 0.2))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha= 0.2))\n",
    "    # (4,4) >> filter size\n",
    "    # strides = (2,2) >> Convolutional layers, that how NN understand images\n",
    "\n",
    "    # Create Final output layer and forming image shape\n",
    "    # the shape (3, (3,3)) reffers to image shape :\n",
    "    #    >>>  img_shape = (img_width, img_height, channels)\n",
    "    model.add(Conv2D(3, (3,3), activation= 'tanh', padding = 'same'))\n",
    "\n",
    "    #\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bt6QsJCW0mcI"
   },
   "source": [
    "## **4) Building Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2JzEAPv0lKt",
    "outputId": "1201760c-1ce4-4c88-b2a5-91aca4d4ea94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 262145    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 780,545\n",
      "Trainable params: 780,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Create input layer and filter and stride layer. That makes NN understand image\n",
    "    model.add(Conv2D(64, (3,3), padding = 'same', input_shape = img_shape))\n",
    "\n",
    "    # Adding activation function\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(Conv2D(256, (3,3), padding = 'same'))\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Create output layer\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbcKcKmA0q2S"
   },
   "source": [
    "## **5) Connecting Neural Networks to build GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q0Ue3TEd0xLy"
   },
   "outputs": [],
   "source": [
    "GAN = Sequential()\n",
    "discriminator.trainable = False\n",
    "GAN.add(generator)\n",
    "GAN.add(discriminator)\n",
    "\n",
    "GAN.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EPqU8dZDaQmE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 32, 32, 3)         1466115   \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 780545    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,246,660\n",
      "Trainable params: 1,466,115\n",
      "Non-trainable params: 780,545\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WaNhBDwRwTG"
   },
   "source": [
    "## **6) Outputting Images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HQEJ0WbjRppy"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "## **7) Outputting Images**\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import imageio\n",
    "import PIL\n",
    "\n",
    "save_name = 0.00000000\n",
    "\n",
    "def save_imgs(epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    global save_name\n",
    "    save_name += 0.00000001\n",
    "    print(\"%.8f\" % save_name)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            # axs[i,j].imshow(gen_imgs[cnt])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"generated_images/%.8f.png\" % save_name)\n",
    "    print('saved')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE57Lk5V0xs2"
   },
   "source": [
    "## **7) Training GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "egSJJvik00Iq"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(64, 28, 28)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHARON~1\\AppData\\Local\\Temp/ipykernel_30136/1104406085.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\SHARON~1\\AppData\\Local\\Temp/ipykernel_30136/1104406085.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#Train discriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0md_loss_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0md_loss_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfakes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2091\u001b[0m                                                     class_weight)\n\u001b[0;32m   2092\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2093\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2095\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(64, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def train(epochs, batch_size=64, save_interval=200):\n",
    "  (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "  # print(X_train.shape)\n",
    "  #Rescale data between -1 and 1\n",
    "  X_train = X_train / 127.5 -1.\n",
    "  # X_train = np.expand_dims(X_train, axis=3)\n",
    "  # print(X_train.shape)\n",
    "\n",
    "  #Create our Y for our Neural Networks\n",
    "  valid = np.ones((batch_size, 1))\n",
    "  fakes = np.zeros((batch_size, 1))\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    #Get Random Batch\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    #Generate Fake Images\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    #Train discriminator\n",
    "    d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, fakes)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    \n",
    "    #inverse y label\n",
    "    g_loss = GAN.train_on_batch(noise, valid)\n",
    "\n",
    "    print(\"******* %d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100* d_loss[1], g_loss))\n",
    "\n",
    "    if(epoch % save_interval) == 0:\n",
    "      save_imgs(epoch)\n",
    "\n",
    "  # print(valid)\n",
    "\n",
    "\n",
    "train(30000, batch_size=64, save_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GS9wDLeRLUOB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Rlgu8g9Lik9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "po-jSQoN1Azl"
   },
   "source": [
    "### **8) Making GIF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPShgQpg1EMy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Cifar10_Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
